# @package _global_

agent:
  config:
    modules:
      masked_mimic_target_pose_model:
        _target_: protomotions.agents.common.mlp.MLP_WithNorm
        _recursive_: false
        num_in: ${env.config.masked_mimic.masked_mimic_target_pose.num_obs_per_sparse_target_pose}
        num_out: ${agent.config.model.config.encoder.config.transformer_token_size}
        config:
          obs_key: masked_mimic_target_poses
          mask_key: masked_mimic_target_poses_masks
          normalize_obs: true
          norm_clamp_value: 5

          operations:
            - type: reshape
              new_shape:
                - -1
                - ${env.config.masked_mimic.masked_mimic_target_pose.num_obs_per_sparse_target_pose}  # encoded obs per pose
            - type: encode
            - type: reshape
              new_shape:
                - batch_size
                - ${eval:${env.config.masked_mimic.masked_mimic_target_pose.num_future_steps}+1} #+1 for long-range future pose
                - ${agent.config.model.config.encoder.config.transformer_token_size}  # encoded obs per pose
          layers:
            - units: 256
              activation: relu
              use_layer_norm: false
            - units: 256
              activation: relu
              use_layer_norm: false
      historical_pose_obs_model:
        _target_: protomotions.agents.common.mlp.MLP_WithNorm
        _recursive_: false
        num_in: ${eval:${robot.self_obs_size}+1}
        num_out: ${agent.config.model.config.encoder.config.transformer_token_size}
        config:
          obs_key: historical_pose_obs
          mask_key: null
          normalize_obs: true
          norm_clamp_value: 5

          operations:
            - type: reshape
              new_shape:
                - -1
                - ${eval:${robot.self_obs_size}+1}  # encoded obs per pose
            - type: encode
            - type: reshape
              new_shape:
                - batch_size
                - ${env.config.masked_mimic.historical_obs.num_historical_conditioned_steps} #+1 for long-range future pose
                - ${agent.config.model.config.encoder.config.transformer_token_size}  # encoded obs per pose
          layers:
            - units: 256
              activation: relu
              use_layer_norm: false
            - units: 256
              activation: relu
              use_layer_norm: false

    model:
      config:
        encoder:
          _target_: protomotions.agents.common.transformer.Transformer
          _recursive_: False
          num_out: ${robot.number_of_actions}
          config:
            transformer_token_size: ${.latent_dim}
            latent_dim: 512
            ff_size: 1024
            num_layers: 4
            num_heads: 4
            dropout: 0

            activation: relu
            use_layer_norm: false

            input_models:
              obs_mlp:
                _target_: protomotions.agents.common.mlp.MLP_WithNorm
                _recursive_: False
                num_in: ${robot.self_obs_size}
                num_out: ${...transformer_token_size}
                config:
                  mask_key: null
                  obs_key: self_obs
                  normalize_obs: True
                  norm_clamp_value: 5
                  layers:
                    - units: 256
                      activation: relu
                      use_layer_norm: false
                    - units: 256
                      activation: relu
                      use_layer_norm: false
              masked_mimic_target_poses: ${agent.config.modules.masked_mimic_target_pose_model}
              historical_pose_obs: ${agent.config.modules.historical_pose_obs_model}
